[{"content":"Handling Weakness When it comes to programming, I\u0026rsquo;m very visually orientated. I struggle to grasp theoretical concepts that don\u0026rsquo;t have physical real-world analogues.\nYeah. I love analogies. Too much.\nFunctional programming. I struggle to visualise it. I love its elegance (when it works), but I am so unproductive in it. I know it has a steep learning curve, but I\u0026rsquo;m not joking. I don\u0026rsquo;t think I\u0026rsquo;m smart enough to use it efficiently, at least not in a professional capacity.\nYou can add to that list:\nKubernetes Authentication Cryptography Probably 90% of networking Cloud architecture ML dev UI/UX Healthy Constraints Largely, I\u0026rsquo;ve been able to look at those things and go, \u0026ldquo;It\u0026rsquo;s okay. I probably didn\u0026rsquo;t want to be a network administrator anyway\u0026rdquo;. There is a blessing in constraints; if the road is as wide as it is long, we wouldn\u0026rsquo;t know which direction to go.\nSome of that other stuff is harder to look past. \u0026ldquo;How am I gonna be a decent software developer if I can\u0026rsquo;t make a decent UI?\u0026rdquo; and I get really caught up on it.\nIt would have been fine for Batman to go to a zoo and look a bat in the eye a few times a week, maybe pet one, and call his phobia dealt with. But he took it too far and became a bat-themed vigilante. But I love that. I want to be like Batman and turn my weaknesses into strengths, face my fears and GET GOOD.\nLike Batman, I\u0026rsquo;ve gone down the rabbit-hole on my weaknesses.\nUnlike Batman, I haven\u0026rsquo;t been as successful.\nI don\u0026rsquo;t want to just be okay at frontend dev, I want it to become a strength. So I muster inspiration, it becomes the focus, I form unrealistic expectations about my progress and I lose inspiration. Rinse and repeat.\nInstead I should let these weaknesses constrain me and redirect me in my strengths to where I can progress. Like gutter guards when bowling; feel the feedback, bounce back, and keep moving forwards. Let your weaknesses provide you with focus.\nWhen to Push That isn\u0026rsquo;t to say you should never front up any weakness. You need to use good judgement.\nSay you suck at cloud architecture.\nHow did you get here? Is it relevant? Can your goals be met another way? If not\u0026hellip;\nWhat do you lack that has produced this weakness? Is it just experience? Do you need to get yourself out there? Or\u0026hellip;\nDo you lack talent and skill too? Does it really grind your mental cogs? Do you catch yourself tuning out because it doesn\u0026rsquo;t engage you? Don\u0026rsquo;t try to force your brain or your personality into something it isn\u0026rsquo;t.\nBe honest with yourself. As before, take the best you can from these limitations.\nAmbidexterity Some weaknesses are present because they are strengths in other areas. They exist on a spectrum. You might not be great at administering organisational policy or configuration, but excel at creating organic community around open-source projects. Maybe people energise you but data doesn\u0026rsquo;t?\nSome things are a left-right brain tug-of-war and it\u0026rsquo;s simply rare to be \u0026ldquo;ambidextrous\u0026rdquo; and have both. Check your weaknesses for corresponding strengths. Let those discoveries motivate you and inspire you and kick that imposter syndrome in the butt.\nOther things exist on that same spectrum and can be changed, but will cost you territory somewhere else. The strengths that make someone a great counsellor may have to be abandoned if they want to be a ring-in CEO who saves companies from the edge of bankruptcy.\nBut what about where you are ambidextrous? If you find something in yourself that is traditionally a rare coupling of strengths, use that in putting yourself that your counterparts are not. Got video-editing chops? Know how to code? How about use that to create dynamic, programmatically generated content!\nAugmenting Weakness Sometimes you just have to eat your vegetables and push through. You need to get familiar with an unintuitive process in a role that you otherwise enjoy. That doesn\u0026rsquo;t mean you tap out and go on the hunt for your unicorn, but it doesn\u0026rsquo;t mean you have to endure it vanilla either.\nFortunately, we live in the age of AI. GPT-4O, Copilot, Gemini and Claude are all advanced enough to search the internet and provide great answers for topics they may not even have training on. RAG is affordable and easy. Let AI be your tutor and translate obtuse documentation for you.\nAI Tools I was messing around with Powershell Universal the other day (for some quick form validation with backend Active Directory commands. I spent a few hours over a week getting into the nitty gritty of form components and schemas.\nOut of curiosity, I tried asking GPT-4O to build me a form with my laundry list of fields and validations. To my surprise, it pumped out several hundred lines of code that only needed two adjustments to build and render successfully. I let it know and the successive builds were perfect every time. Prompting with further changes became quicker than navigating the code and adjusting it by hand.\nAm I a frontend wizard now? Hardly. But it\u0026rsquo;s an augmented weakness now. It gets the job done and it doesn\u0026rsquo;t drain my mental capacity anymore. I can focus on what I\u0026rsquo;m good at.\nSome more AI tools (all free):\nCody (Sourcegraph\u0026rsquo;s AI IDE assistant) Mods (Command-line pipeable AI) Ollama (Offline self-hosted LLMs) What you don\u0026rsquo;t know You don\u0026rsquo;t know what you don\u0026rsquo;t know. GPTs traditionally struggle with complex questions founded on poor understanding of the problem.\nRemember the \u0026ldquo;Chat\u0026rdquo; in Chat-GPT.\nYou don\u0026rsquo;t need to give mega-prompts.\nAsk the right questions. Ask broad questions. Ask smaller questions. If you don\u0026rsquo;t know enough about the problem, don\u0026rsquo;t constrain AI to provide you with a solution that fits your suggested implementation of a solution.\nThe more you understand what you don\u0026rsquo;t know, the better chance you have of learning what you do need to know. It\u0026rsquo;s very easy to learn in the wrong direction.\nCommunity Best for last.\nSometimes you need more organic discussion with specific experience. I.e. a real person. If you have co-workers, ask them, and ask them if they know anyone too.\nAfter your physical circles, try online communities:\nGitHub discussions, issues Relevant subreddits Discord servers you find on Youtube channels Forums (especially if they\u0026rsquo;re Discourse based) LinkedIn (surprisingly) Unlike GPTs who can listen to your thankless questions all day, community works best for everyone when involvement is not transactional, but relational. I\u0026rsquo;m not just talking about manners. You will get more relevant, helpful information when you prioritise relationships, and it will be more enjoyable.\nDon\u0026rsquo;t underestimate the value of individuals. If someone has an answer for you, they likely have other relevant experience that could be useful to you, and you to them. When you do work you\u0026rsquo;re interested in, good at, and can find others of like-mind, you\u0026rsquo;re basically just making friends.\nTech-bros could learn a bit from truckies here. Truck drivers seem to know everyone and they\u0026rsquo;ll \u0026ldquo;know a guy\u0026rdquo; for every job. We think we contribute to community when we share spicy memes or goofy comments with people we don\u0026rsquo;t know on socials, but that\u0026rsquo;s not it. Find your crowd and get to know its people.\nThink about it yourself, if someone asked you if you \u0026ldquo;know a guy\u0026rdquo; in your tech circles. Would you point them to a person or a URL? Let that be your criteria for community.\nSumming up Find out what you\u0026rsquo;re not good at. Determine if you actually need to be good at it. Don\u0026rsquo;t be tempted by Batman\u0026rsquo;s dangling carrots. Use your \u0026ldquo;ambidextrous\u0026rdquo; strengths. Leverage modern tooling. Actively involve yourself in modern community. Most importantly:\nDo you really need to learn Rust? Can you settle for Go?\n","date":"2024-06-16T00:00:00Z","image":"https://calebtrevatt.com/p/getting-good/cover_hu06637c82a47f073597054830d341209f_723215_120x120_fill_q75_box_smart1.jpg","permalink":"https://calebtrevatt.com/p/getting-good/","title":"Getting Good where you're Not"},{"content":"What is it? AI integration is becoming ubiquitous. Warp is pioneering \u0026ldquo;the terminal of the future\u0026rdquo; with AI capabilities built-in. VS Code supports extensions like Github Copilot and Cody, while Zed includes Zed AI. But what if you need a simple, versatile tool to bring AI into any conversation? Checkout Mods. Charm\u0026rsquo;s dev team and community are on a roll, producing some awesome new apps and libraries, and this is no exception. üëÄ\nMods takes the concept of prompting a GPT and brings it to the command line. It even supports piping stdin and stdout! Any output from any command on your terminal, think ls, cat, curl and the like, can become input for Mods. Prompt it with some instructions on how to handle that data and you can either get rich feedback in your terminal or pipe the output for further processing.\nCurious? Here are some examples!\nExamples Rich Markdown Output Mods supports rich colour and formatting out-of-the-box. Install Charm\u0026rsquo;s Glow, set the default output format to markdown and every response will be pretty. ‚ú®\nEvaluate Script Security How about those inherently-unsafe one-liner shell script installers? Now finally safe with Mods! Here\u0026rsquo;s an example in WSL Ubuntu: Piping GitHub API Data Feed it raw JSON data from an API. Here it is running in good old Powershell 5 on Windows 10: Piping to Text-to-Speech What about some text to speech? We can pipe stdout to a text to speech engine. Here\u0026rsquo;s a little example with Wsay, a Windows equivalent to \u0026ldquo;Say\u0026rdquo; on MacOS: https://github.com/p-groarke/wsay üìù Note\u0026hellip;\nIt might be worth considering something a little more natural if you want it to read you bedtime stories. Google text-to-speech might be a better option.\nCalling in a Loop You can even call it in a loop! This will ask for 10 fresh duck haikus. Each iteration is a new conversation. No conversational context; guaranteed freshness. üçÉ\n1 2 3 # 10 ü¶Ü haikus straight to your speakers! 1..10 | % { \u0026#34;Tell me a haiku about ducks\u0026#34; | mods | wsay -o duck_haiku$_.wav } And in Bash, like so:\n1 2 3 4 for i in {1..10} do echo \u0026#34;Haiku time!\u0026#34; | mods | gtts-cli - --output duck_haiku$i.mp3 done For more examples check out the official ones from the Mods repo\nMulti LLM Support Mods supports multiple Large Language Models (LLMs) through multiple providers. Providing an OpenAI API key gets you a pretty quick out-of-box experience. It\u0026rsquo;s already set up to use OpenAI\u0026rsquo;s GPT-4 by default.\nPop open the settings with:\nmods --settings\nNote, you\u0026rsquo;ll have to define a default $EDITOR in your environment variables.\nYou\u0026rsquo;ll be greeted with the mods.yml file. Check out the APIs section. Mods supports:\nOpenAI: GPT-4O, GPT-4, GPT-3.5-Turbo, etc.\nAzure: GPT-4O, GPT-4, GPT-3.5-Turbo, etc.\nPerplexity AI: CodeLlama, Mistral, Claude 3, Sonar, etc.\nGroq: Mixtral, Llama 2, Llama 3, etc.\nRunPod: OpenChat, Ollama, etc (IaaS/SaaS)\nLocal: Llama.cpp, GPT4ALL.cpp, etc. (local - GPU optional!)\nüìù Note\u0026hellip;\nUntil today, I\u0026rsquo;d never tried Groq. Boy is it fast! Evidently, Groq provides significantly faster inference through next-gen hardware: Language Processing Units (LPUs).\nAPI access is free, at least for now. I couldn\u0026rsquo;t find any official pricing anywhere. My guess is they\u0026rsquo;re relying on the free access to spread the word so they sell their chips üçüüí≤\nCheck it out: https://groq.com\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Default model (gpt-3.5-turbo, gpt-4, ggml-gpt4all-j...). default-model: gpt-4 ... apis: openai: base-url: https://api.openai.com/v1 api-key: api-key-env: OPENAI_API_KEY models: gpt-4: aliases: [\u0026#34;4\u0026#34;] max-input-chars: 24500 fallback: gpt-3.5-turbo gpt-4-1106-preview: aliases: [\u0026#34;128k\u0026#34;] max-input-chars: 392000 fallback: gpt-4 ... Configuration is the same for all providers. Provide the base url, desired models, and specify aliases for those models. If you want to use a specific model, call it like this:\n\u0026quot;What is gravity?\u0026quot; | mods --model=\u0026quot;Mixtral\u0026quot;\nYou can also supply -M or --Ask-Model to interactively choose a model (though this seems to be ignored if you pass a prompt non-interactively).\nConversational Memory Nice! Now when I was generating haikus I hard-sold amneisa as a feature for conversational freshness. What if we wanted to remember conversations across commands? Maybe with something more complicated\u0026hellip; Something that can\u0026rsquo;t be done \u0026ldquo;zero-shot\u0026rdquo;?\nWell thankfully Mods has some handy parameters that allow resuming and managing conversations:\n1 2 3 4 5 6 7 8 -c, --continue Continue from the last response or a given save title. -C, --continue-last Continue from the last response. -l, --list Lists saved conversations. -t, --title Saves the current conversation with the given title. -d, --delete Deletes a saved conversation with the given title or ID. -s, --show Show a saved conversation with the given title or ID. -S, --show-last Show the last saved conversation. A Really Heavy Example Here\u0026rsquo;s a PowerShell commandlet I made (along with 59 other functions necessary to make it work). I use it to provision temporary user accounts for student exams at my workplace.\nNew-Exam -D 10/03 -FT 8 -TT 11 -Alloc 105 -U 5 -CC \u0026quot;10SCI\u0026quot;\nMy bespoke exam provisioning commandlet\nFor the sake of your screen real-estate I\u0026rsquo;ve used the parameter aliases, but I will explain in a moment!\nEssentially this commandlet:\nSets Active Directory account logon hours\nSets account expiration time\nSets group membership (for exam conditions)\nValidates users by name or student ID and fetches AD attributes\nPopulates an HTML login sheet template with user data and exam details\nMerges the sheets into a PDF\nAnd it saves me HOURS.\nBut one thing remains that sucks like a parasite at my remaining time and brain power:\nThe exam login requests themselves.\nThe problem is that login reqeuests aren\u0026rsquo;t consistent. Requests come in all shapes and sizes. Some come with multiple updates across a chain of emails. Some come in concise bullet points. Some say \u0026ldquo;next Wednesday\u0026rdquo;. Others say \u0026ldquo;19/05/2024\u0026rdquo;.\nWhat an excellent opportunity for AI ‚Äì and for Mods!\nInterfacing with the Commandlet So first I told Mods how to commandlet. works and the inputs and outputs I expect:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $Instructions = \u0026#34;New-Exam is a powershell commandlet. \u0026gt; It is used to create temporary Active Directory accounts for exams. \u0026gt; \u0026gt; Here\u0026#39;s an example: \u0026gt; New-Exam -D 10/03 -FT 8 -TT 11 -U 5 -S \u0026#34;10SCI\u0026#34; -C \u0026gt; \u0026gt; -D is \u0026#34;date\u0026#34; \u0026gt; -FT is \u0026#34;from time\u0026#34; \u0026gt; -TT is \u0026#34;to time\u0026#34; \u0026gt; -U is \u0026#34;user count\u0026#34; \u0026gt; -S is \u0026#34;subject\u0026#34; \u0026gt; -C is \u0026#34;conditions\u0026#34; (do not include) \u0026gt; \u0026gt; Follow the format of the example. \u0026gt; Output the exact command to run, no extra information or context. \u0026gt; If data is missing or invalid, output: \u0026gt; \u0026#39;echo \u0026#34;Invalid data: ___\u0026#34; \u0026gt; where blank is the invalid or missing data. $Instructions | mods --title=\u0026#34;New Exam\u0026#34; üìù Note\u0026hellip;\n\u0026ldquo;Conditions\u0026rdquo; above I asked it not to include. The conditions aren\u0026rsquo;t difficult to pass, but for the sake of experimentation I left them out. Fortunately, if a mandatory parameter is left out of a PowerShell commandlet it will be prompted at runtime. Good to know!\nPushing Jobs Then I gave it an exam login request email.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $Message = \u0026#34;Hi IT team! \u0026gt; \u0026gt; We have a science exam on tomorrow. \u0026gt; \u0026gt; Please can we have four logins? \u0026gt; \u0026gt; - Disable internet \u0026gt; - No USB access \u0026gt; - They can have spellcheck \u0026gt; \u0026gt; Start: 10:30, Finish: 12PM \u0026gt; \u0026gt; Kind regards, \u0026gt; \u0026gt; Dane Joe\u0026#34; $ Message | mods --continue=\u0026#34;New Exam\u0026#34; | Invoke-Expression Retrospect Running the commandlet is now as easy as \u0026ldquo;continuing\u0026rdquo; the conversation with the previous context (the instructions) and piping it to PowerShell\u0026rsquo;s Invoke-Expression. Super easy!\nI actually have a lot of validation built into the commandlet. Like what if the exam is on a Saturday? Shouldn\u0026rsquo;t happen. What if the subject is only offered in grade 12 and a grade 10 student is taking it? Shouldn\u0026rsquo;t happen.\nI\u0026rsquo;m a little wonky about trusting validation to the mysterious Latent Space. Getting different answers to the same question asked twice makes me a little twitchy\u0026hellip; But technically all of those validation rules could be applied at the prompt context level instead.\nCould this all be solved with a simple HTML form? Definitely! Yes.\nShould it? Mmhmm. Probably!\nAs a general rule, if you want automation to produce consistently reliable outputs, you need consistently reliable inputs. AI \u0026ldquo;magics\u0026rdquo; away some of this, but it still requires some massaging and testing.\nIn a situation like this, if a user form was not an option, it would be a great candidate for an AI flow in LangChain or Flowise. I\u0026rsquo;m hoping to take a look at these soon!\nWrapping Up Mods is a great bridge between AI LLMs great demo of some cheap ad-hoc glue to try things out. Great for protyping, proof-of-concept, or ad-hoc formatting/parsing/sorting and the like. Perfect for someone like me who frequently gets caught up on the implementation details. With mods I can rapidly prototype in English, adjusting for desired behaviour with additional prompts. Once I\u0026rsquo;ve got a proof of concept, I can lay down something more solid.\nIf an HTTP form This is actually a great use case for LangChain or Flowise. Hoping to take a look at these soon!\nSo \u0026ldquo;Don\u0026rsquo;t be shy, give Mods a try.\u0026rdquo;\n","date":"2024-05-30T00:00:00Z","image":"https://calebtrevatt.com/p/ai-for-the-shell/cover_hu42b1e5fa58b9a97d592da02d34f3ec8e_64364_120x120_fill_q75_box_smart1.jpg","permalink":"https://calebtrevatt.com/p/ai-for-the-shell/","title":"AI for the Shell"}]